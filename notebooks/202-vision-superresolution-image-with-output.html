
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Single Image Super Resolution with OpenVINO™ &#8212; OpenVINO™  documentation</title>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    <script src="../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom.js"></script>
    <script src="../_static/js/graphs.js"></script>
    <script src="../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/notebooks/202-vision-superresolution-image-with-output.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Video Super Resolution with OpenVINO™" href="202-vision-superresolution-video-with-output.html" />
    <link rel="prev" title="Monodepth Estimation with OpenVINO" href="201-vision-monodepth-with-output.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/get-started-guide.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/openvino-docs/index.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/openvino-docs/index.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notebooks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks-installation.html">
   Installation of OpenVINO™ Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="001-hello-world-with-output.html">
   Hello Image Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002-openvino-api-with-output.html">
   OpenVINO™ Runtime API Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003-hello-segmentation-with-output.html">
   Hello Image Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004-hello-detection-with-output.html">
   Hello Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="101-tensorflow-to-openvino-with-output.html">
   Convert a TensorFlow Model to OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="102-pytorch-onnx-to-openvino-with-output.html">
   Convert a PyTorch Model to ONNX and OpenVINO™ IR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="103-paddle-onnx-to-openvino-classification-with-output.html">
   Convert a PaddlePaddle Model to ONNX and OpenVINO™ IR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="104-model-tools-with-output.html">
   Working with Open Model Zoo Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="105-language-quantize-bert-with-output.html">
   Quantize NLP models with Post-Training Optimization Tool ​in OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="106-auto-device-with-output.html">
   Automatic Device Selection with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="107-speech-recognition-quantization-with-output.html">
   Quantize Speech Recognition Models with OpenVINO™ Post-Training Optimization Tool ​
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="110-ct-segmentation-quantize-nncf-with-output.html">
   Quantize a Segmentation Model and Show Live Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="110-ct-segmentation-quantize-with-output.html">
   Quantize a Segmentation Model and Show Live Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="111-detection-quantization-with-output.html">
   Object Detection Quantization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="112-pytorch-post-training-quantization-nncf-with-output.html">
   Post-Training Quantization of PyTorch models with NNCF
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="113-image-classification-quantization-with-output.html">
   Quantization of Image Classification Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="114-quantization-simplified-mode-with-output.html">
   INT8 Quantization with Post-training Optimization Tool (POT) in Simplified Mode tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="115-async-api-with-output.html">
   Asynchronous Inference with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="201-vision-monodepth-with-output.html">
   Monodepth Estimation with OpenVINO
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Single Image Super Resolution with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="202-vision-superresolution-video-with-output.html">
   Video Super Resolution with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="203-meter-reader-with-output.html">
   Industrial Meter Reader
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="204-named-entity-recognition-with-output.html">
   Document Entity Extraction with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="205-vision-background-removal-with-output.html">
   Image Background Removal with U^2-Net and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="206-vision-paddlegan-anime-with-output.html">
   Photos to Anime with PaddleGAN and OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="207-vision-paddlegan-superresolution-with-output.html">
   Super Resolution with PaddleGAN and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="208-optical-character-recognition-with-output.html">
   Optical Character Recognition (OCR) with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="209-handwritten-ocr-with-output.html">
   Handwritten Chinese and Japanese OCR with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="210-ct-scan-live-inference-with-output.html">
   Live Inference and Benchmark CT-scan Data with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="211-speech-to-text-with-output.html">
   Speech to Text with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="212-onnx-style-transfer-with-output.html">
   Style Transfer on ONNX Models with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="214-vision-paddle-classification-with-output.html">
   PaddlePaddle Image Classification with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="215-image-inpainting-with-output.html">
   Image In-painting with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="216-license-plate-recognition-with-output.html">
   License Plate Recognition with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="217-vision-deblur-with-output.html">
   Deblur Photos with DeblurGAN-v2 and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="218-vehicle-detection-and-recognition-with-output.html">
   Vehicle Detection And Recognition with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="219-knowledge-graphs-conve-with-output.html">
   OpenVINO optimizations for Knowledge graphs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="220-yolov5-accuracy-check-and-quantization-with-output.html">
   Quantize the Ultralytics YOLOv5 model and check accuracy using the OpenVINO POT API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="221-machine-translation-with-output.html">
   Machine translation demo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="222-vision-image-colorization-with-output.html">
   Image Colorization with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="223-gpt2-text-prediction-with-output.html">
   GPT-2 Text Prediction with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="301-tensorflow-training-openvino-pot-with-output.html">
   Post-Training Quantization with TensorFlow Classification Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="301-tensorflow-training-openvino-with-output.html">
   From Training to Deployment with TensorFlow and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="302-pytorch-quantization-aware-training-with-output.html">
   Quantization Aware Training with NNCF, using PyTorch framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="305-tensorflow-quantization-aware-training-with-output.html">
   Quantization Aware Training with NNCF, using TensorFlow Framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="401-object-detection-with-output.html">
   Live Object Detection with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="402-pose-estimation-with-output.html">
   Live Human Pose Estimation with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="403-action-recognition-webcam-with-output.html">
   Human Action Recognition with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="405-paddle-ocr-webcam-with-output.html">
   PaddleOCR with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebook_utils-with-output.html">
   Notebook Utils
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preparation">
   Preparation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imports">
     Imports
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#settings">
     Settings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#functions">
     Functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-superresolution-model">
   Load the Superresolution Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-and-show-the-input-image">
   Load and Show the Input Image
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#superresolution-on-a-crop-of-the-image">
   Superresolution on a Crop of the Image
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#crop-the-input-image-once">
     Crop the Input Image once.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reshape-resize-crop-for-model-input">
     Reshape/Resize Crop for Model Input
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#do-inference">
     Do Inference
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#show-and-save-results">
     Show and Save Results
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#save-superresolution-and-bicubic-image-crop">
       Save Superresolution and Bicubic Image Crop
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#write-animated-gif-with-bicubic-superresolution-comparison">
       Write Animated GIF with Bicubic/Superresolution Comparison
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-a-video-with-sliding-bicubic-superresolution-comparison">
       Create a Video with Sliding Bicubic/Superresolution Comparison
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#superresolution-on-full-input-image">
   Superresolution on full input image
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compute-patches">
     Compute patches
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Do Inference
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#save-superresolution-image-and-the-bicubic-image">
     Save superresolution image and the bicubic image
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="single-image-super-resolution-with-openvino">
<h1>Single Image Super Resolution with OpenVINO™<a class="headerlink" href="#single-image-super-resolution-with-openvino" title="Permalink to this headline">¶</a></h1>
<p>Super Resolution is the process of enhancing the quality of an image by
increasing the pixel count using deep learning. This notebook shows the
Single Image Super Resolution (SISR) which takes just one low resolution
image. A model called
<a class="reference external" href="https://docs.openvino.ai/latest/omz_models_model_single_image_super_resolution_1032.html">single-image-super-resolution-1032</a>,
which is available in Open Model Zoo, is used in this tutorial. It is
based on the research paper cited below.</p>
<p>Y. Liu et al., <a class="reference external" href="https://arxiv.org/abs/1807.06779">“An Attention-Based Approach for Single Image Super
Resolution,”</a> 2018 24th
International Conference on Pattern Recognition (ICPR), 2018,
pp. 2777-2784, doi: 10.1109/ICPR.2018.8545760.</p>
<section id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Permalink to this headline">¶</a></h2>
<section id="imports">
<h3>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import time
import urllib
from pathlib import Path

import cv2
import matplotlib.pyplot as plt
import numpy as np
from IPython.display import HTML, FileLink
from IPython.display import Image as DisplayImage
from IPython.display import Pretty, ProgressBar, clear_output, display
from PIL import Image
from openvino.runtime import Core
</pre></div>
</div>
</section>
<section id="settings">
<h3>Settings<a class="headerlink" href="#settings" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Device to use for inference. For example, &quot;CPU&quot;, or &quot;GPU&quot;.
DEVICE = &quot;CPU&quot;
# 1032: 4x superresolution, 1033: 3x superresolution
MODEL_FILE = &quot;model/single-image-super-resolution-1032.xml&quot;
model_name = os.path.basename(MODEL_FILE)
model_xml_path = Path(MODEL_FILE).with_suffix(&quot;.xml&quot;)
</pre></div>
</div>
</section>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def write_text_on_image(image: np.ndarray, text: str) -&gt; np.ndarray:
    &quot;&quot;&quot;
    Write the specified text in the top left corner of the image
    as white text with a black border.

    :param image: image as numpy arry with HWC shape, RGB or BGR
    :param text: text to write
    :return: image with written text, as numpy array
    &quot;&quot;&quot;
    font = cv2.FONT_HERSHEY_PLAIN
    org = (20, 20)
    font_scale = 4
    font_color = (255, 255, 255)
    line_type = 1
    font_thickness = 2
    text_color_bg = (0, 0, 0)
    x, y = org

    image = cv2.UMat(image)
    (text_w, text_h), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
    result_im = cv2.rectangle(image, org, (x + text_w, y + text_h), text_color_bg, -1)

    textim = cv2.putText(
        result_im,
        text,
        (x, y + text_h + font_scale - 1),
        font,
        font_scale,
        font_color,
        font_thickness,
        line_type,
    )
    return textim.get()


def load_image(path: str) -&gt; np.ndarray:
    &quot;&quot;&quot;
    Loads an image from `path` and returns it as BGR numpy array.

    :param path: path to an image filename or url
    :return: image as numpy array, with BGR channel order
    &quot;&quot;&quot;
    if path.startswith(&quot;http&quot;):
        # Set User-Agent to Mozilla because some websites block requests
        # with User-Agent Python.
        request = urllib.request.Request(path, headers={&quot;User-Agent&quot;: &quot;Mozilla/5.0&quot;})
        response = urllib.request.urlopen(request)
        array = np.asarray(bytearray(response.read()), dtype=&quot;uint8&quot;)
        image = cv2.imdecode(array, -1)  # Loads the image as BGR.
    else:
        image = cv2.imread(path)
    return image


def convert_result_to_image(result) -&gt; np.ndarray:
    &quot;&quot;&quot;
    Convert network result of floating point numbers to image with integer
    values from 0-255. Values outside this range are clipped to 0 and 255.

    :param result: a single superresolution network result in N,C,H,W shape
    &quot;&quot;&quot;
    result = result.squeeze(0).transpose(1, 2, 0)
    result *= 255
    result[result &lt; 0] = 0
    result[result &gt; 255] = 255
    result = result.astype(np.uint8)
    return result


def to_rgb(image_data) -&gt; np.ndarray:
    &quot;&quot;&quot;
    Convert image_data from BGR to RGB
    &quot;&quot;&quot;
    return cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)
</pre></div>
</div>
</section>
</section>
<section id="load-the-superresolution-model">
<h2>Load the Superresolution Model<a class="headerlink" href="#load-the-superresolution-model" title="Permalink to this headline">¶</a></h2>
<p>The Super Resolution model expects two inputs: the input image and a
bicubic interpolation of the input image to the target size of
1920x1080. It returns the super resolution version of the image in
1920x1800 (for the default superresolution model (1032)).</p>
<p>Load the model in OpenVINO Runtime with <code class="docutils literal notranslate"><span class="pre">ie.read_model</span></code>, compile it
for the specified device with <code class="docutils literal notranslate"><span class="pre">ie.compile_model</span></code>, and get information
about the network inputs and outputs.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ie = Core()
model = ie.read_model(model=model_xml_path)
compiled_model = ie.compile_model(model=model, device_name=DEVICE)

# Network inputs and outputs are dictionaries. Get the keys for the
# dictionaries.
original_image_key, bicubic_image_key = compiled_model.inputs
output_key = compiled_model.output(0)

# Get the expected input and target shape. The `.dims[2:]` returns the height
# and width. The `resize` function of OpenCV expects the shape as (width, height),
# so reverse the shape with `[::-1]` and convert it to a tuple.
input_height, input_width = list(original_image_key.shape)[2:]
target_height, target_width = list(bicubic_image_key.shape)[2:]

upsample_factor = int(target_height / input_height)

print(f&quot;The network expects inputs with a width of {input_width}, &quot; f&quot;height of {input_height}&quot;)
print(f&quot;The network returns images with a width of {target_width}, &quot; f&quot;height of {target_height}&quot;)

print(
    f&quot;The image sides are upsampled by a factor of {upsample_factor}. &quot;
    f&quot;The new image is {upsample_factor**2} times as large as the &quot;
    &quot;original image&quot;
)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">network</span> <span class="n">expects</span> <span class="n">inputs</span> <span class="k">with</span> <span class="n">a</span> <span class="n">width</span> <span class="n">of</span> <span class="mi">480</span><span class="p">,</span> <span class="n">height</span> <span class="n">of</span> <span class="mi">270</span>
<span class="n">The</span> <span class="n">network</span> <span class="n">returns</span> <span class="n">images</span> <span class="k">with</span> <span class="n">a</span> <span class="n">width</span> <span class="n">of</span> <span class="mi">1920</span><span class="p">,</span> <span class="n">height</span> <span class="n">of</span> <span class="mi">1080</span>
<span class="n">The</span> <span class="n">image</span> <span class="n">sides</span> <span class="n">are</span> <span class="n">upsampled</span> <span class="n">by</span> <span class="n">a</span> <span class="n">factor</span> <span class="n">of</span> <span class="mf">4.</span> <span class="n">The</span> <span class="n">new</span> <span class="n">image</span> <span class="ow">is</span> <span class="mi">16</span> <span class="n">times</span> <span class="k">as</span> <span class="n">large</span> <span class="k">as</span> <span class="n">the</span> <span class="n">original</span> <span class="n">image</span>
</pre></div>
</div>
</section>
<section id="load-and-show-the-input-image">
<h2>Load and Show the Input Image<a class="headerlink" href="#load-and-show-the-input-image" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p><strong>NOTE</strong>: For the best results, use raw images (like TIFF, BMP or
PNG). Compressed images (like JPEG) may appear distorted after
processing with the super resolution model.</p>
</div></blockquote>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>IMAGE_PATH = Path(&quot;data/tower.jpg&quot;)
OUTPUT_PATH = Path(&quot;output/&quot;)

os.makedirs(str(OUTPUT_PATH), exist_ok=True)
full_image = load_image(str(IMAGE_PATH))

# Uncomment these lines to load a raw image as BGR.
# import rawpy
# with rawpy.imread(IMAGE_PATH) as raw:
#     full_image = raw.postprocess()[:,:,(2,1,0)]

plt.imshow(to_rgb(full_image))
print(f&quot;Showing full image with width {full_image.shape[1]} &quot; f&quot;and height {full_image.shape[0]}&quot;)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Showing</span> <span class="n">full</span> <span class="n">image</span> <span class="k">with</span> <span class="n">width</span> <span class="mi">5976</span> <span class="ow">and</span> <span class="n">height</span> <span class="mi">3770</span>
</pre></div>
</div>
<img alt="../_images/202-vision-superresolution-image-with-output_10_1.png" src="../_images/202-vision-superresolution-image-with-output_10_1.png" />
</section>
<section id="superresolution-on-a-crop-of-the-image">
<h2>Superresolution on a Crop of the Image<a class="headerlink" href="#superresolution-on-a-crop-of-the-image" title="Permalink to this headline">¶</a></h2>
<section id="crop-the-input-image-once">
<h3>Crop the Input Image once.<a class="headerlink" href="#crop-the-input-image-once" title="Permalink to this headline">¶</a></h3>
<p>Crop the network input size. Give the X (width) and Y (height)
coordinates for the top left corner of the crop. Set the <code class="docutils literal notranslate"><span class="pre">CROP_FACTOR</span></code>
variable to 2 to make a crop that is larger than the network input size
(this only works with the <code class="docutils literal notranslate"><span class="pre">single-image-super-resolution-1032</span></code> model).
The crop will be downsampled before propagating to the network. This is
useful for very high resolution images, where a crop of the network
input size is too small to show enough information. It can also improve
the result. Keep in mind that with a <code class="docutils literal notranslate"><span class="pre">CROP_FACTOR</span></code> or 2 the net
upsampling factor will be halved. If the superresolution network
increases the side lengths of the image by a factor of 4, it upsamples a
480x270 crop to 1920x1080. With a <code class="docutils literal notranslate"><span class="pre">CROP_FACTOR</span></code> of 2, a 960x540 crop
is upsampled to the same 1920x1080: the side lengths are twice as large
as the crop size.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Set `CROP_FACTOR` to 2 to crop with twice the input width and height
# This only works with the 1032 (4x) superresolution model!
# Set it to 1 to crop the image with the exact input size.
CROP_FACTOR = 2
adjusted_upsample_factor = upsample_factor // CROP_FACTOR

image_id = &quot;flag&quot;  # A tag to recognize the saved images.
starty = 3200
startx = 0

# Perform the crop.
image_crop = full_image[
    starty : starty + input_height * CROP_FACTOR,
    startx : startx + input_width * CROP_FACTOR,
]

# Show the cropped image.
print(f&quot;Showing image crop with width {image_crop.shape[1]} and &quot; f&quot;height {image_crop.shape[0]}.&quot;)
plt.imshow(to_rgb(image_crop));
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Showing</span> <span class="n">image</span> <span class="n">crop</span> <span class="k">with</span> <span class="n">width</span> <span class="mi">960</span> <span class="ow">and</span> <span class="n">height</span> <span class="mf">540.</span>
</pre></div>
</div>
<img alt="../_images/202-vision-superresolution-image-with-output_12_1.png" src="../_images/202-vision-superresolution-image-with-output_12_1.png" />
</section>
<section id="reshape-resize-crop-for-model-input">
<h3>Reshape/Resize Crop for Model Input<a class="headerlink" href="#reshape-resize-crop-for-model-input" title="Permalink to this headline">¶</a></h3>
<p>The input image is resized to a network input size, and reshaped to
(N,C,H,W) (N=number of images, C=number of channels, H=height, W=width).
The image is also resized to the network output size, with bicubic
interpolation. This bicubic image is the second input to the network.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Resize the image to the target shape with bicubic interpolation.
bicubic_image = cv2.resize(
    src=image_crop, dsize=(target_width, target_height), interpolation=cv2.INTER_CUBIC
)

# If required, resize the image to the input image shape.
if CROP_FACTOR &gt; 1:
    image_crop = cv2.resize(src=image_crop, dsize=(input_width, input_height))

# Reshape the images from (H,W,C) to (N,C,H,W).
input_image_original = np.expand_dims(image_crop.transpose(2, 0, 1), axis=0)
input_image_bicubic = np.expand_dims(bicubic_image.transpose(2, 0, 1), axis=0)
</pre></div>
</div>
</section>
<section id="do-inference">
<h3>Do Inference<a class="headerlink" href="#do-inference" title="Permalink to this headline">¶</a></h3>
<p>Do inference and convert the inference result to an <code class="docutils literal notranslate"><span class="pre">RGB</span></code> image.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>result = compiled_model(
    {
        original_image_key.any_name: input_image_original,
        bicubic_image_key.any_name: input_image_bicubic,
    }
)[output_key]

# Get inference result as numpy array and reshape to image shape and data type
result_image = convert_result_to_image(result)
</pre></div>
</div>
</section>
<section id="show-and-save-results">
<h3>Show and Save Results<a class="headerlink" href="#show-and-save-results" title="Permalink to this headline">¶</a></h3>
<p>Show the bicubic image and the enhanced superresolution image.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(30, 15))
ax[0].imshow(to_rgb(bicubic_image))
ax[1].imshow(to_rgb(result_image))
ax[0].set_title(&quot;Bicubic&quot;)
ax[1].set_title(&quot;Superresolution&quot;)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s1">&#39;Superresolution&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/202-vision-superresolution-image-with-output_18_1.png" src="../_images/202-vision-superresolution-image-with-output_18_1.png" />
<section id="save-superresolution-and-bicubic-image-crop">
<h4>Save Superresolution and Bicubic Image Crop<a class="headerlink" href="#save-superresolution-and-bicubic-image-crop" title="Permalink to this headline">¶</a></h4>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Add a text with &quot;SUPER&quot; or &quot;BICUBIC&quot; to the superresolution or bicubic image.
image_super = write_text_on_image(image=result_image, text=&quot;SUPER&quot;)
image_bicubic = write_text_on_image(image=bicubic_image, text=&quot;BICUBIC&quot;)

# Store the image and the results.
crop_image_path = Path(f&quot;{OUTPUT_PATH.stem}/{image_id}_{adjusted_upsample_factor}x_crop.png&quot;)
superres_image_path = Path(
    f&quot;{OUTPUT_PATH.stem}/{image_id}_{adjusted_upsample_factor}x_crop_superres.png&quot;
)
bicubic_image_path = Path(
    f&quot;{OUTPUT_PATH.stem}/{image_id}_{adjusted_upsample_factor}x_crop_bicubic.png&quot;
)
cv2.imwrite(filename=str(crop_image_path), img=image_crop, params=[cv2.IMWRITE_PNG_COMPRESSION, 0])
cv2.imwrite(
    filename=str(superres_image_path), img=image_super, params=[cv2.IMWRITE_PNG_COMPRESSION, 0]
)
cv2.imwrite(
    filename=str(bicubic_image_path), img=image_bicubic, params=[cv2.IMWRITE_PNG_COMPRESSION, 0]
)
print(f&quot;Images written to directory: {OUTPUT_PATH}&quot;)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Images</span> <span class="n">written</span> <span class="n">to</span> <span class="n">directory</span><span class="p">:</span> <span class="n">output</span>
</pre></div>
</div>
</section>
<section id="write-animated-gif-with-bicubic-superresolution-comparison">
<h4>Write Animated GIF with Bicubic/Superresolution Comparison<a class="headerlink" href="#write-animated-gif-with-bicubic-superresolution-comparison" title="Permalink to this headline">¶</a></h4>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(image_bicubic.shape)
print(image_super.shape)

result_pil = Image.fromarray(to_rgb(image_super))
bicubic_pil = Image.fromarray(to_rgb(image_bicubic))
gif_image_path = Path(f&quot;{OUTPUT_PATH.stem}/{image_id}_comparison_{adjusted_upsample_factor}x.gif&quot;)

result_pil.save(
    fp=str(gif_image_path),
    format=&quot;GIF&quot;,
    append_images=[bicubic_pil],
    save_all=True,
    duration=1000,
    loop=0,
)

# The `DisplayImage(str(gif_image_path))` function does not work in Colab.
DisplayImage(data=open(gif_image_path, &quot;rb&quot;).read(), width=1920 // 2)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">1080</span><span class="p">,</span> <span class="mi">1920</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="p">(</span><span class="mi">1080</span><span class="p">,</span> <span class="mi">1920</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/202-vision-superresolution-image-with-output_22_1.png"><img alt="../_images/202-vision-superresolution-image-with-output_22_1.png" src="../_images/202-vision-superresolution-image-with-output_22_1.png" style="width: 960px;" /></a>
</section>
<section id="create-a-video-with-sliding-bicubic-superresolution-comparison">
<h4>Create a Video with Sliding Bicubic/Superresolution Comparison<a class="headerlink" href="#create-a-video-with-sliding-bicubic-superresolution-comparison" title="Permalink to this headline">¶</a></h4>
<p>This may take a while. For the video, the superresolution and bicubic
image are resized by a factor of 2 to improve processing speed. This
gives an indication of the superresolution effect. The video is saved as
an <code class="docutils literal notranslate"><span class="pre">.avi</span></code> file. You can click on the link to download the video, or
open it directly from the images directory, and play it locally.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>FOURCC = cv2.VideoWriter_fourcc(*&quot;MJPG&quot;)

result_video_path = Path(
    f&quot;{OUTPUT_PATH.stem}/{image_id}_crop_comparison_{adjusted_upsample_factor}x.avi&quot;
)
video_target_height, video_target_width = (
    result_image.shape[0] // 2,
    result_image.shape[1] // 2,
)

out_video = cv2.VideoWriter(
    filename=str(result_video_path),
    fourcc=FOURCC,
    fps=90,
    frameSize=(video_target_width, video_target_height),
)

resized_result_image = cv2.resize(src=result_image, dsize=(video_target_width, video_target_height))
resized_bicubic_image = cv2.resize(
    src=bicubic_image, dsize=(video_target_width, video_target_height)
)

progress_bar = ProgressBar(total=video_target_width)
progress_bar.display()

for i in range(video_target_width):
    # Create a frame where the left part (until i pixels width) contains the
    # superresolution image, and the right part (from i pixels width) contains
    # the bicubic image.
    comparison_frame = np.hstack(
        (
            resized_result_image[:, :i, :],
            resized_bicubic_image[:, i:, :],
        )
    )
    # Create a small black border line between the superresolution
    # and bicubic part of the image.
    comparison_frame[:, i - 1 : i + 1, :] = 0
    out_video.write(image=comparison_frame)
    progress_bar.progress = i
    progress_bar.update()
out_video.release()
clear_output()

video_link = FileLink(result_video_path)
video_link.html_link_str = &quot;&lt;a href=&#39;%s&#39; download&gt;%s&lt;/a&gt;&quot;
display(HTML(f&quot;The video has been saved to {video_link._repr_html_()}&quot;))
</pre></div>
</div>
The video has been saved to output/flag_crop_comparison_2x.avi<br></section>
</section>
</section>
<section id="superresolution-on-full-input-image">
<h2>Superresolution on full input image<a class="headerlink" href="#superresolution-on-full-input-image" title="Permalink to this headline">¶</a></h2>
<p>Superresolution on the full image is done by dividing the image into
patches of equal size, doing superresolution on each path, and then
stitching the resulting patches together again. For this demo, patches
near the border of the image are ignored.</p>
<p>Adjust the <code class="docutils literal notranslate"><span class="pre">CROPLINES</span></code> setting in the next cell if you see boundary
effects.</p>
<section id="compute-patches">
<h3>Compute patches<a class="headerlink" href="#compute-patches" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Set the number of lines to crop from the network result to prevent
# boundary effects. The value of `CROPLINES` should be an integer &gt;= 1.
CROPLINES = 10
# See Superresolution on one crop of the image for description of `CROP_FACTOR`.
CROP_FACTOR = 2

full_image_height, full_image_width = full_image.shape[:2]

# Compute x and y coordinates of left top of image tiles.
x_coords = list(range(0, full_image_width, input_width * CROP_FACTOR - CROPLINES * 2))
while full_image_width - x_coords[-1] &lt; input_width * CROP_FACTOR:
    x_coords.pop(-1)
y_coords = list(range(0, full_image_height, input_height * CROP_FACTOR - CROPLINES * 2))
while full_image_height - y_coords[-1] &lt; input_height * CROP_FACTOR:
    y_coords.pop(-1)

# Compute the width and height to crop the full image. The full image is
# cropped at the border to tiles of the input size.
crop_width = x_coords[-1] + input_width * CROP_FACTOR
crop_height = y_coords[-1] + input_height * CROP_FACTOR

# Compute the width and height of the target superresolution image.
new_width = (
    x_coords[-1] * (upsample_factor // CROP_FACTOR)
    + target_width
    - CROPLINES * 2 * (upsample_factor // CROP_FACTOR)
)
new_height = (
    y_coords[-1] * (upsample_factor // CROP_FACTOR)
    + target_height
    - CROPLINES * 2 * (upsample_factor // CROP_FACTOR)
)
print(f&quot;The output image will have a width of {new_width} &quot; f&quot;and a height of {new_height}&quot;)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">output</span> <span class="n">image</span> <span class="n">will</span> <span class="n">have</span> <span class="n">a</span> <span class="n">width</span> <span class="n">of</span> <span class="mi">11280</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">height</span> <span class="n">of</span> <span class="mi">7280</span>
</pre></div>
</div>
</section>
<section id="id1">
<h3>Do Inference<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>The code below reads one patch of the image at a time. Each patch is
reshaped to the network input shape and upsampled with bicubic
interpolation to the target shape. Both the original and the bicubic
images are propagated through the network. The network result is a numpy
array with floating point values, with a shape of <code class="docutils literal notranslate"><span class="pre">(1,3,1920,1080)</span></code>.
This array is converted to an 8-bit image with the <code class="docutils literal notranslate"><span class="pre">(1080,1920,3)</span></code>
shape and written to a <code class="docutils literal notranslate"><span class="pre">full_superresolution_image</span></code>. The bicubic image
is written to a <code class="docutils literal notranslate"><span class="pre">full_bicubic_image</span></code> for comparison. A progress bar
shows the progress of the process. Inference time is measured, as well
as total time to process each patch.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>start_time = time.perf_counter()
patch_nr = 0
num_patches = len(x_coords) * len(y_coords)
progress_bar = ProgressBar(total=num_patches)
progress_bar.display()

# Crop image to fit tiles of the input size.
full_image_crop = full_image.copy()[:crop_height, :crop_width, :]

# Create an empty array of the target size.
full_superresolution_image = np.empty((new_height, new_width, 3), dtype=np.uint8)

# Create a bicubic upsampled image of the target size for comparison.
full_bicubic_image = cv2.resize(
    src=full_image_crop[CROPLINES:-CROPLINES, CROPLINES:-CROPLINES, :],
    dsize=(new_width, new_height),
    interpolation=cv2.INTER_CUBIC,
)

total_inference_duration = 0
for y in y_coords:
    for x in x_coords:
        patch_nr += 1

        # Crop the input image.
        image_crop = full_image_crop[
            y : y + input_height * CROP_FACTOR,
            x : x + input_width * CROP_FACTOR,
        ]

        # Resize the images to the target shape with bicubic interpolation
        bicubic_image = cv2.resize(
            src=image_crop,
            dsize=(target_width, target_height),
            interpolation=cv2.INTER_CUBIC,
        )

        if CROP_FACTOR &gt; 1:
            image_crop = cv2.resize(src=image_crop, dsize=(input_width, input_height))

        input_image_original = np.expand_dims(image_crop.transpose(2, 0, 1), axis=0)

        input_image_bicubic = np.expand_dims(bicubic_image.transpose(2, 0, 1), axis=0)

        # Do inference.
        inference_start_time = time.perf_counter()

        result = compiled_model(
            {
                original_image_key.any_name: input_image_original,
                bicubic_image_key.any_name: input_image_bicubic,
            }
        )[output_key]

        inference_stop_time = time.perf_counter()
        inference_duration = inference_stop_time - inference_start_time
        total_inference_duration += inference_duration

        # Reshape an inference result to the image shape and the data type.
        result_image = convert_result_to_image(result)

        # Add the inference result of this patch to the full superresolution
        # image.
        adjusted_upsample_factor = upsample_factor // CROP_FACTOR
        new_y = y * adjusted_upsample_factor
        new_x = x * adjusted_upsample_factor
        full_superresolution_image[
            new_y : new_y + target_height - CROPLINES * adjusted_upsample_factor * 2,
            new_x : new_x + target_width - CROPLINES * adjusted_upsample_factor * 2,
        ] = result_image[
            CROPLINES * adjusted_upsample_factor : -CROPLINES * adjusted_upsample_factor,
            CROPLINES * adjusted_upsample_factor : -CROPLINES * adjusted_upsample_factor,
            :,
        ]

        progress_bar.progress = patch_nr
        progress_bar.update()

        if patch_nr % 10 == 0:
            clear_output(wait=True)
            progress_bar.display()
            display(
                Pretty(
                    f&quot;Processed patch {patch_nr}/{num_patches}. &quot;
                    f&quot;Inference time: {inference_duration:.2f} seconds &quot;
                    f&quot;({1/inference_duration:.2f} FPS)&quot;
                )
            )

end_time = time.perf_counter()
duration = end_time - start_time
clear_output(wait=True)
print(
    f&quot;Processed {num_patches} patches in {duration:.2f} seconds. &quot;
    f&quot;Total patches per second (including processing): &quot;
    f&quot;{num_patches/duration:.2f}.\nInference patches per second: &quot;
    f&quot;{num_patches/total_inference_duration:.2f} &quot;
)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Processed</span> <span class="mi">42</span> <span class="n">patches</span> <span class="ow">in</span> <span class="mf">7.58</span> <span class="n">seconds</span><span class="o">.</span> <span class="n">Total</span> <span class="n">patches</span> <span class="n">per</span> <span class="n">second</span> <span class="p">(</span><span class="n">including</span> <span class="n">processing</span><span class="p">):</span> <span class="mf">5.54</span><span class="o">.</span>
<span class="n">Inference</span> <span class="n">patches</span> <span class="n">per</span> <span class="n">second</span><span class="p">:</span> <span class="mf">8.10</span>
</pre></div>
</div>
</section>
<section id="save-superresolution-image-and-the-bicubic-image">
<h3>Save superresolution image and the bicubic image<a class="headerlink" href="#save-superresolution-image-and-the-bicubic-image" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>full_superresolution_image_path = Path(
    f&quot;{OUTPUT_PATH.stem}/full_superres_{adjusted_upsample_factor}x.jpg&quot;
)
full_bicubic_image_path = Path(f&quot;{OUTPUT_PATH.stem}/full_bicubic_{adjusted_upsample_factor}x.jpg&quot;)

cv2.imwrite(str(full_superresolution_image_path), full_superresolution_image)
cv2.imwrite(str(full_bicubic_image_path), full_bicubic_image);
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>bicubic_link = FileLink(full_bicubic_image_path)
image_link = FileLink(full_superresolution_image_path)
bicubic_link.html_link_str = &quot;&lt;a href=&#39;%s&#39; download&gt;%s&lt;/a&gt;&quot;
image_link.html_link_str = &quot;&lt;a href=&#39;%s&#39; download&gt;%s&lt;/a&gt;&quot;
display(
    HTML(
        &quot;The images are saved in the images directory. You can also download &quot;
        &quot;them by clicking on these links:&quot;
        f&quot;&lt;ul&gt;&lt;li&gt;{image_link._repr_html_()}&lt;li&gt;{bicubic_link._repr_html_()}&quot;
    )
)
</pre></div>
</div>
The images are saved in the images directory. You can also download them by clicking on these links:<ul><li>output/full_bicubic_2x.jpg<br></section>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="201-vision-monodepth-with-output.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="202-vision-superresolution-video-with-output.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>
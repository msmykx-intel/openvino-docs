
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>PaddlePaddle Image Classification with OpenVINO™ &#8212; OpenVINO™  documentation</title>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    <script src="../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom.js"></script>
    <script src="../_static/js/graphs.js"></script>
    <script src="../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/notebooks/214-vision-paddle-classification-with-output.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Image In-painting with OpenVINO™" href="215-image-inpainting-with-output.html" />
    <link rel="prev" title="Style Transfer on ONNX Models with OpenVINO™" href="212-onnx-style-transfer-with-output.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/get-started-guide.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/openvino-docs/index.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/openvino-docs/index.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notebooks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks-installation.html">
   Installation of OpenVINO™ Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="001-hello-world-with-output.html">
   Hello Image Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002-openvino-api-with-output.html">
   OpenVINO™ Runtime API Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003-hello-segmentation-with-output.html">
   Hello Image Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004-hello-detection-with-output.html">
   Hello Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="101-tensorflow-to-openvino-with-output.html">
   Convert a TensorFlow Model to OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="102-pytorch-onnx-to-openvino-with-output.html">
   Convert a PyTorch Model to ONNX and OpenVINO™ IR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="103-paddle-onnx-to-openvino-classification-with-output.html">
   Convert a PaddlePaddle Model to ONNX and OpenVINO™ IR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="104-model-tools-with-output.html">
   Working with Open Model Zoo Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="105-language-quantize-bert-with-output.html">
   Quantize NLP models with Post-Training Optimization Tool ​in OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="106-auto-device-with-output.html">
   Automatic Device Selection with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="107-speech-recognition-quantization-with-output.html">
   Quantize Speech Recognition Models with OpenVINO™ Post-Training Optimization Tool ​
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="110-ct-segmentation-quantize-nncf-with-output.html">
   Quantize a Segmentation Model and Show Live Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="110-ct-segmentation-quantize-with-output.html">
   Quantize a Segmentation Model and Show Live Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="111-detection-quantization-with-output.html">
   Object Detection Quantization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="112-pytorch-post-training-quantization-nncf-with-output.html">
   Post-Training Quantization of PyTorch models with NNCF
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="113-image-classification-quantization-with-output.html">
   Quantization of Image Classification Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="114-quantization-simplified-mode-with-output.html">
   INT8 Quantization with Post-training Optimization Tool (POT) in Simplified Mode tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="115-async-api-with-output.html">
   Asynchronous Inference with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="201-vision-monodepth-with-output.html">
   Monodepth Estimation with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="202-vision-superresolution-image-with-output.html">
   Single Image Super Resolution with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="202-vision-superresolution-video-with-output.html">
   Video Super Resolution with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="203-meter-reader-with-output.html">
   Industrial Meter Reader
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="204-named-entity-recognition-with-output.html">
   Document Entity Extraction with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="205-vision-background-removal-with-output.html">
   Image Background Removal with U^2-Net and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="206-vision-paddlegan-anime-with-output.html">
   Photos to Anime with PaddleGAN and OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="207-vision-paddlegan-superresolution-with-output.html">
   Super Resolution with PaddleGAN and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="208-optical-character-recognition-with-output.html">
   Optical Character Recognition (OCR) with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="209-handwritten-ocr-with-output.html">
   Handwritten Chinese and Japanese OCR with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="210-ct-scan-live-inference-with-output.html">
   Live Inference and Benchmark CT-scan Data with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="211-speech-to-text-with-output.html">
   Speech to Text with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="212-onnx-style-transfer-with-output.html">
   Style Transfer on ONNX Models with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   PaddlePaddle Image Classification with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="215-image-inpainting-with-output.html">
   Image In-painting with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="216-license-plate-recognition-with-output.html">
   License Plate Recognition with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="217-vision-deblur-with-output.html">
   Deblur Photos with DeblurGAN-v2 and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="218-vehicle-detection-and-recognition-with-output.html">
   Vehicle Detection And Recognition with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="219-knowledge-graphs-conve-with-output.html">
   OpenVINO optimizations for Knowledge graphs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="220-yolov5-accuracy-check-and-quantization-with-output.html">
   Quantize the Ultralytics YOLOv5 model and check accuracy using the OpenVINO POT API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="221-machine-translation-with-output.html">
   Machine translation demo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="222-vision-image-colorization-with-output.html">
   Image Colorization with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="223-gpt2-text-prediction-with-output.html">
   GPT-2 Text Prediction with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="301-tensorflow-training-openvino-pot-with-output.html">
   Post-Training Quantization with TensorFlow Classification Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="301-tensorflow-training-openvino-with-output.html">
   From Training to Deployment with TensorFlow and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="302-pytorch-quantization-aware-training-with-output.html">
   Quantization Aware Training with NNCF, using PyTorch framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="305-tensorflow-quantization-aware-training-with-output.html">
   Quantization Aware Training with NNCF, using TensorFlow Framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="401-object-detection-with-output.html">
   Live Object Detection with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="402-pose-estimation-with-output.html">
   Live Human Pose Estimation with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="403-action-recognition-webcam-with-output.html">
   Human Action Recognition with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="405-paddle-ocr-webcam-with-output.html">
   PaddleOCR with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebook_utils-with-output.html">
   Notebook Utils
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import">
   Import
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-the-mobilenetv3-large-x1-0-model">
   Download the MobileNetV3_large_x1_0 Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-the-callback-function-for-postprocessing">
   Define the callback function for postprocessing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-the-model">
   Read the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#integrate-preprocessing-steps-into-the-execution-graph-with-preprocessing-api">
   Integrate preprocessing steps into the execution graph with Preprocessing API
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-inference">
   Run Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#performance-hints-latency-and-throughput">
   Performance Hints: Latency and Throughput
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measure-performance-with-benchmark-app">
   Measure Performance with benchmark_app
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="paddlepaddle-image-classification-with-openvino">
<h1>PaddlePaddle Image Classification with OpenVINO™<a class="headerlink" href="#paddlepaddle-image-classification-with-openvino" title="Permalink to this headline">¶</a></h1>
<p>This demo shows how to run a MobileNetV3 Large PaddePaddle model, using
OpenVINO Runtime. Instead of exporting the PaddlePaddle model to ONNX
and converting to OpenVINO Intermediate Representation (OpenVINO IR)
format using Model Optimizer, you can now read the Paddle model directly
without conversion.</p>
<section id="import">
<h2>Import<a class="headerlink" href="#import" title="Permalink to this headline">¶</a></h2>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Downloading model
from pathlib import Path
import os
import urllib.request
import tarfile

# Inference
from openvino.runtime import Core

# Preprocessing
import cv2
import numpy as np
from openvino.preprocess import PrePostProcessor, ResizeAlgorithm
from openvino.runtime import Layout, Type, AsyncInferQueue, PartialShape

# Visualization of the results
import time
import json
from IPython.display import Image
</pre></div>
</div>
</section>
<section id="download-the-mobilenetv3-large-x1-0-model">
<h2>Download the MobileNetV3_large_x1_0 Model<a class="headerlink" href="#download-the-mobilenetv3-large-x1-0-model" title="Permalink to this headline">¶</a></h2>
<p>Download the pre-trained model directly from the server. For more
detailed information about the pre-trained model, refer to the
<a class="reference external" href="https://github.com/PaddlePaddle/PaddleClas/blob/release/2.2/deploy/lite/readme_en.md">PaddleClas
documentation</a>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>mobilenet_url = &quot;https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/inference/MobileNetV3_large_x1_0_infer.tar&quot;
mobilenetv3_model_path = Path(&quot;model/MobileNetV3_large_x1_0_infer/inference.pdmodel&quot;)
if mobilenetv3_model_path.is_file():
    print(&quot;Model MobileNetV3_large_x1_0 already exists&quot;)
else:
    # Download the model from the server, and untar it.
    print(&quot;Downloading the MobileNetV3_large_x1_0_infer model (20Mb)... May take a while...&quot;)
    # Create a directory.
    os.makedirs(&quot;model&quot;)
    urllib.request.urlretrieve(mobilenet_url, &quot;model/MobileNetV3_large_x1_0_infer.tar&quot;)
    print(&quot;Model Downloaded&quot;)

    file = tarfile.open(&quot;model/MobileNetV3_large_x1_0_infer.tar&quot;)
    res = file.extractall(&quot;model&quot;)
    file.close()
    if (not res):
        print(f&quot;Model Extracted to {mobilenetv3_model_path}.&quot;)
    else:
        print(&quot;Error Extracting the model. Please check the network.&quot;)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Downloading</span> <span class="n">the</span> <span class="n">MobileNetV3_large_x1_0_infer</span> <span class="n">model</span> <span class="p">(</span><span class="mi">20</span><span class="n">Mb</span><span class="p">)</span><span class="o">...</span> <span class="n">May</span> <span class="n">take</span> <span class="n">a</span> <span class="k">while</span><span class="o">...</span>
<span class="n">Model</span> <span class="n">Downloaded</span>
<span class="n">Model</span> <span class="n">Extracted</span> <span class="n">to</span> <span class="n">model</span><span class="o">/</span><span class="n">MobileNetV3_large_x1_0_infer</span><span class="o">/</span><span class="n">inference</span><span class="o">.</span><span class="n">pdmodel</span><span class="o">.</span>
</pre></div>
</div>
</section>
<section id="define-the-callback-function-for-postprocessing">
<h2>Define the callback function for postprocessing<a class="headerlink" href="#define-the-callback-function-for-postprocessing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def callback(infer_request, info) -&gt; None:
    &quot;&quot;&quot;
    Define the callback function for postprocessing

    :param: infer_request: the infer_request object
            info: a tuple includes the submitting time of infer request and iteration of inference
    :retuns:
            None
    &quot;&quot;&quot;
    global total_time
    submit_time, i = info
    imagenet_classes = json.loads(open(&quot;utils/imagenet_class_index.json&quot;).read())
    predictions = next(iter(infer_request.results.values()))
    indices = np.argsort(-predictions[0])
    if (i == 0):
        # Calculate the first inference time
        first_latency = (time.time() - submit_time) * 1000
        print(&quot;first inference latency: {:.2f} ms&quot;.format(first_latency))
        for n in range(5):
            print(
                &quot;class name: {}, probability: {:.5f}&quot;
                .format(imagenet_classes[str(list(indices)[n])][1], predictions[0][list(indices)[n]])
            )
        total_time = total_time + first_latency
    else:
        latency = (time.time() - submit_time) * 1000
        total_time = total_time + latency
</pre></div>
</div>
</section>
<section id="read-the-model">
<h2>Read the model<a class="headerlink" href="#read-the-model" title="Permalink to this headline">¶</a></h2>
<p>OpenVINO Runtime reads the <code class="docutils literal notranslate"><span class="pre">PaddlePaddle</span></code> model directly.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Intialize OpenVINO Runtime with Core()
ie = Core()
# MobileNetV3_large_x1_0
model = ie.read_model(mobilenetv3_model_path)
# Get the information of input and output layers.
input_layer = model.input(0)
output_layer = model.output(0)
</pre></div>
</div>
</section>
<section id="integrate-preprocessing-steps-into-the-execution-graph-with-preprocessing-api">
<h2>Integrate preprocessing steps into the execution graph with Preprocessing API<a class="headerlink" href="#integrate-preprocessing-steps-into-the-execution-graph-with-preprocessing-api" title="Permalink to this headline">¶</a></h2>
<p>If your input data does not fit perfectly in the model input tensor,
additional operations/steps are needed to transform the data to a format
expected by the model. These operations are known as “preprocessing”.
Preprocessing steps are integrated into the execution graph and
performed on the selected device(s) (CPU/GPU/VPU/etc.) rather than
always executed on CPU. This improves utilization on the selected
device(s).</p>
<p>For more information, refer to the overview of <a class="reference external" href="https://docs.openvino.ai/latest/openvino_docs_OV_Runtime_UG_Preprocessing_Overview.html">Preprocessing
API</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>filename = &quot;../001-hello-world/data/coco.jpg&quot;
test_image = cv2.imread(filename)
test_image = np.expand_dims(test_image, 0) / 255
_, h, w, _ = test_image.shape

# Adjust model input shape to improve the performance.
model.reshape({input_layer.any_name: PartialShape([1, 3, 224, 224])})
ppp = PrePostProcessor(model)
# Set input tensor information:
# - The `input()` function provides information about a single model input.
# - Layout of data is &quot;NHWC&quot;.
# - Set static spatial dimensions to input tensor to resize from.
ppp.input().tensor() \
    .set_spatial_static_shape(h, w) \
    .set_layout(Layout(&quot;NHWC&quot;))
inputs = model.inputs
# Here, it is assumed that the model has &quot;NCHW&quot; layout for input.
ppp.input().model().set_layout(Layout(&quot;NCHW&quot;))
# Do prepocessing:
# - Apply linear resize from tensor spatial dims to model spatial dims.
# - Subtract mean from each channel.
# - Divide each pixel data to appropriate scale value.
ppp.input().preprocess() \
    .resize(ResizeAlgorithm.RESIZE_LINEAR, 224, 224) \
    .mean([0.485, 0.456, 0.406]) \
    .scale([0.229, 0.224, 0.225])
# Set output tensor information:
# - Precision of a tensor is supposed to be &#39;f32&#39;.
ppp.output().tensor().set_element_type(Type.f32)
# Apply preprocessing to modify the original &#39;model&#39;.
model = ppp.build()
</pre></div>
</div>
</section>
<section id="run-inference">
<h2>Run Inference<a class="headerlink" href="#run-inference" title="Permalink to this headline">¶</a></h2>
<p>Use Auto Device (or AUTO in short) plugin as the device name to delegate
device selection to OpenVINO. AUTO internally recognizes and selects
devices from among Intel CPU and GPU depending on the device
capabilities and the characteristics of the model(s) (for example,
precision). Then, it assigns inference requests to the best device. AUTO
starts inference immediately on the CPU and then transparently shifts to
the GPU (or VPU) once it is ready, dramatically reducing time to first
inference.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>total_time = 0
# Check the available devices in your system.
devices = ie.available_devices
for device in devices:
    device_name = ie.get_property(device, &quot;FULL_DEVICE_NAME&quot;)
    print(f&quot;{device}: {device_name}&quot;)

# Load the model to a device selected by AUTO from the available devices list.
compiled_model = ie.compile_model(model=model, device_name=&quot;AUTO&quot;)
# Create an infer request queue.
infer_queue = AsyncInferQueue(compiled_model)
infer_queue.set_callback(callback)
start = time.time()
# Do inference.
infer_queue.start_async({input_layer.any_name: test_image}, (time.time(), 0))
infer_queue.wait_all()
Image(filename=filename)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CPU</span><span class="p">:</span> <span class="n">Intel</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="n">Core</span><span class="p">(</span><span class="n">TM</span><span class="p">)</span> <span class="n">i9</span><span class="o">-</span><span class="mi">10920</span><span class="n">X</span> <span class="n">CPU</span> <span class="o">@</span> <span class="mf">3.50</span><span class="n">GHz</span>
<span class="n">first</span> <span class="n">inference</span> <span class="n">latency</span><span class="p">:</span> <span class="mf">20.23</span> <span class="n">ms</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Labrador_retriever</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.59148</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">flat</span><span class="o">-</span><span class="n">coated_retriever</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.11678</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Staffordshire_bullterrier</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.04089</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Newfoundland</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.02689</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Tibetan_mastiff</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.01735</span>
</pre></div>
</div>
<img alt="../_images/214-vision-paddle-classification-with-output_12_1.jpg" src="../_images/214-vision-paddle-classification-with-output_12_1.jpg" />
</section>
<section id="performance-hints-latency-and-throughput">
<h2>Performance Hints: Latency and Throughput<a class="headerlink" href="#performance-hints-latency-and-throughput" title="Permalink to this headline">¶</a></h2>
<p>Throughput and latency are some of the most widely used metrics that
measure the overall performance of an application.</p>
<ul class="simple">
<li><p><strong>Latency</strong> measures inference time (ms) required to process a single
input or First inference.</p></li>
<li><p>To calculate <strong>throughput</strong>, divide number of inputs that were
processed by the processing time.</p></li>
</ul>
<p>High-level Performance Hints in OpenVINO are the new way to configure
the performance with the portability in mind. Performance Hints will let
the device configure itself, rather than map the application needs to
the low-level performance settings, and keep an associated application
logic to configure each possible device separately.</p>
<p>For more information, see <a class="reference external" href="https://docs.openvino.ai/latest/openvino_docs_OV_UG_Performance_Hints.html">High-level Performance
Hints</a>.</p>
<p><strong>Run Inference with “LATENCY” Performance Hint</strong></p>
<p>It is possible to define application-specific performance settings with
a config key, letting the device adjust to achieve better <code class="docutils literal notranslate"><span class="pre">LATENCY</span></code>
oriented performance.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>loop = 100
total_time = 0
# AUTO sets device config based on hints.
compiled_model = ie.compile_model(model=model, device_name=&quot;AUTO&quot;, config={&quot;PERFORMANCE_HINT&quot;: &quot;LATENCY&quot;})
infer_queue = AsyncInferQueue(compiled_model)
# Implement AsyncInferQueue Python API to boost the performance in Async mode.
infer_queue.set_callback(callback)
# Run inference for 100 times to get the average FPS.
start_time = time.time()
for i in range(loop):
    infer_queue.start_async({input_layer.any_name: test_image}, (time.time(), i))
infer_queue.wait_all()
end_time = time.time()
# Calculate the average FPS\n&quot;,
fps = loop / (end_time - start_time)
print(&quot;throughput: {:.2f} fps&quot;.format(fps))
print(&quot;average latency: {:.2f} ms&quot;.format(total_time / loop))
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">first</span> <span class="n">inference</span> <span class="n">latency</span><span class="p">:</span> <span class="mf">13.83</span> <span class="n">ms</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Labrador_retriever</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.59148</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">flat</span><span class="o">-</span><span class="n">coated_retriever</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.11678</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Staffordshire_bullterrier</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.04089</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Newfoundland</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.02689</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Tibetan_mastiff</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.01735</span>
<span class="n">throughput</span><span class="p">:</span> <span class="mf">123.72</span> <span class="n">fps</span>
<span class="n">average</span> <span class="n">latency</span><span class="p">:</span> <span class="mf">13.42</span> <span class="n">ms</span>
</pre></div>
</div>
<p><strong>Run Inference with “TRHOUGHPUT” Performance Hint</strong></p>
<p>It is possible to define application-specific performance settings with
a config key, letting the device adjust to achieve better <code class="docutils literal notranslate"><span class="pre">THROUGHPUT</span></code>
performance.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>total_time = 0
# AUTO sets device config based on hints.
compiled_model = ie.compile_model(model=model, device_name=&quot;AUTO&quot;, config={&quot;PERFORMANCE_HINT&quot;: &quot;THROUGHPUT&quot;})
infer_queue = AsyncInferQueue(compiled_model)
infer_queue.set_callback(callback)
start_time = time.time()
for i in range(loop):
    infer_queue.start_async({input_layer.any_name: test_image}, (time.time(), i))
infer_queue.wait_all()
end_time = time.time()
# Calculate the average FPS\n&quot;,
fps = loop / (end_time - start_time)
print(&quot;throughput: {:.2f} fps&quot;.format(fps))
print(&quot;average latency: {:.2f} ms&quot;.format(total_time / loop))
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">first</span> <span class="n">inference</span> <span class="n">latency</span><span class="p">:</span> <span class="mf">20.99</span> <span class="n">ms</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Labrador_retriever</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.59148</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">flat</span><span class="o">-</span><span class="n">coated_retriever</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.11678</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Staffordshire_bullterrier</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.04089</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Newfoundland</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.02689</span>
<span class="k">class</span> <span class="nc">name</span><span class="p">:</span> <span class="n">Tibetan_mastiff</span><span class="p">,</span> <span class="n">probability</span><span class="p">:</span> <span class="mf">0.01735</span>
<span class="n">throughput</span><span class="p">:</span> <span class="mf">266.60</span> <span class="n">fps</span>
<span class="n">average</span> <span class="n">latency</span><span class="p">:</span> <span class="mf">19.78</span> <span class="n">ms</span>
</pre></div>
</div>
</section>
<section id="measure-performance-with-benchmark-app">
<h2>Measure Performance with benchmark_app<a class="headerlink" href="#measure-performance-with-benchmark-app" title="Permalink to this headline">¶</a></h2>
<p>To generate more accurate performance measurements, use <a class="reference external" href="https://docs.openvino.ai/latest/openvino_inference_engine_tools_benchmark_tool_README.html">Benchmark
Tool</a>
in OpenVINO.</p>
<p>You can trigger the “Performance hint” by using <code class="docutils literal notranslate"><span class="pre">-hint</span></code> parameter,
which instructs the OpenVINO device plugin to use the best
network-specific settings for <code class="docutils literal notranslate"><span class="pre">latency</span></code> OR <code class="docutils literal notranslate"><span class="pre">throughput</span></code>.</p>
<blockquote>
<div><p><strong>NOTE</strong>: The performance results from <code class="docutils literal notranslate"><span class="pre">benchmark_app</span></code> exclude
“compilation and load time” of a model.</p>
</div></blockquote>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># &#39;latency&#39;: device performance optimized for LATENCY.
! benchmark_app -m $mobilenetv3_model_path -data_shape [1,3,224,224] -hint &quot;latency&quot;
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>[Step 1/11] Parsing and validating input arguments
[ WARNING ]  -nstreams default value is determined automatically for a device. Although the automatic selection usually provides a reasonable performance, but it still may be non-optimal for some cases, for more information look at README.
[Step 2/11] Loading OpenVINO
[ INFO ] OpenVINO:
         API version............. 2022.1.0-7019-cdb9bec7210-releases/2022/1
[ INFO ] Device info
         CPU
         openvino_intel_cpu_plugin version 2022.1
         Build................... 2022.1.0-7019-cdb9bec7210-releases/2022/1

[Step 3/11] Setting device configuration
[Step 4/11] Reading network files
[ INFO ] Read model took 46.19 ms
[Step 5/11] Resizing network to match image sizes and given batch
[ INFO ] Network batch size: ?
[Step 6/11] Configuring input of the model
[ INFO ] Model input &#39;inputs&#39; precision u8, dimensions ([N,C,H,W]): ? 3 224 224
[ INFO ] Model output &#39;save_infer_model/scale_0.tmp_1&#39; precision f32, dimensions ([...]): ? 1000
[Step 7/11] Loading the model to the device
[ INFO ] Compile model took 129.59 ms
[Step 8/11] Querying optimal runtime parameters
[ INFO ] DEVICE: CPU
[ INFO ]   AVAILABLE_DEVICES  , [&#39;&#39;]
[ INFO ]   RANGE_FOR_ASYNC_INFER_REQUESTS  , (1, 1, 1)
[ INFO ]   RANGE_FOR_STREAMS  , (1, 24)
[ INFO ]   FULL_DEVICE_NAME  , Intel(R) Core(TM) i9-10920X CPU @ 3.50GHz
[ INFO ]   OPTIMIZATION_CAPABILITIES  , [&#39;WINOGRAD&#39;, &#39;FP32&#39;, &#39;FP16&#39;, &#39;INT8&#39;, &#39;BIN&#39;, &#39;EXPORT_IMPORT&#39;]
[ INFO ]   CACHE_DIR  ,
[ INFO ]   NUM_STREAMS  , 1
[ INFO ]   INFERENCE_NUM_THREADS  , 0
[ INFO ]   PERF_COUNT  , False
[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS  , 0
[Step 9/11] Creating infer requests and preparing input data
[ INFO ] Create 1 infer requests took 0.07 ms
[ WARNING ] No input files were given for input &#39;inputs&#39;!. This input will be filled with random values!
[ INFO ] Fill input &#39;inputs&#39; with random values
[Step 10/11] Measuring performance (Start inference asynchronously, 1 inference requests, inference only: False, limits: 60000 ms duration)
[ INFO ] Benchmarking in full mode (inputs filling are included in measurement loop).
[ INFO ] First inference took 24.17 ms
[Step 11/11] Dumping statistics report
Count:          26352 iterations
Duration:       60004.47 ms
Latency:
    AVG:        2.21 ms
    MIN:        2.06 ms
    MAX:        3.05 ms
Throughput: 439.17 FPS
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># &#39;throughput&#39; or &#39;tput&#39;: device performance optimized for THROUGHPUT.
! benchmark_app -m $mobilenetv3_model_path -data_shape [1,3,224,224] -hint &quot;throughput&quot;
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>[Step 1/11] Parsing and validating input arguments
[ WARNING ]  -nstreams default value is determined automatically for a device. Although the automatic selection usually provides a reasonable performance, but it still may be non-optimal for some cases, for more information look at README.
[Step 2/11] Loading OpenVINO
[ INFO ] OpenVINO:
         API version............. 2022.1.0-7019-cdb9bec7210-releases/2022/1
[ INFO ] Device info
         CPU
         openvino_intel_cpu_plugin version 2022.1
         Build................... 2022.1.0-7019-cdb9bec7210-releases/2022/1

[Step 3/11] Setting device configuration
[Step 4/11] Reading network files
[ INFO ] Read model took 28.16 ms
[Step 5/11] Resizing network to match image sizes and given batch
[ INFO ] Network batch size: ?
[Step 6/11] Configuring input of the model
[ INFO ] Model input &#39;inputs&#39; precision u8, dimensions ([N,C,H,W]): ? 3 224 224
[ INFO ] Model output &#39;save_infer_model/scale_0.tmp_1&#39; precision f32, dimensions ([...]): ? 1000
[Step 7/11] Loading the model to the device
[ INFO ] Compile model took 170.80 ms
[Step 8/11] Querying optimal runtime parameters
[ INFO ] DEVICE: CPU
[ INFO ]   AVAILABLE_DEVICES  , [&#39;&#39;]
[ INFO ]   RANGE_FOR_ASYNC_INFER_REQUESTS  , (1, 1, 1)
[ INFO ]   RANGE_FOR_STREAMS  , (1, 24)
[ INFO ]   FULL_DEVICE_NAME  , Intel(R) Core(TM) i9-10920X CPU @ 3.50GHz
[ INFO ]   OPTIMIZATION_CAPABILITIES  , [&#39;WINOGRAD&#39;, &#39;FP32&#39;, &#39;FP16&#39;, &#39;INT8&#39;, &#39;BIN&#39;, &#39;EXPORT_IMPORT&#39;]
[ INFO ]   CACHE_DIR  ,
[ INFO ]   NUM_STREAMS  , 1
[ INFO ]   INFERENCE_NUM_THREADS  , 0
[ INFO ]   PERF_COUNT  , False
[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS  , 0
[Step 9/11] Creating infer requests and preparing input data
[ INFO ] Create 6 infer requests took 1.76 ms
[ WARNING ] No input files were given for input &#39;inputs&#39;!. This input will be filled with random values!
[ INFO ] Fill input &#39;inputs&#39; with random values
[Step 10/11] Measuring performance (Start inference asynchronously, 6 inference requests, inference only: False, limits: 60000 ms duration)
[ INFO ] Benchmarking in full mode (inputs filling are included in measurement loop).
[ INFO ] First inference took 27.98 ms
[Step 11/11] Dumping statistics report
Count:          55429 iterations
Duration:       60007.19 ms
Latency:
    AVG:        6.30 ms
    MIN:        2.89 ms
    MAX:        54.13 ms
Throughput: 923.71 FPS
</pre></div>
</div>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="212-onnx-style-transfer-with-output.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="215-image-inpainting-with-output.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>
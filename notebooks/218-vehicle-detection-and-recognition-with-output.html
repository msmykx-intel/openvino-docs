
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Vehicle Detection And Recognition with OpenVINO™ &#8212; OpenVINO™  documentation</title>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    <script src="../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom.js"></script>
    <script src="../_static/js/graphs.js"></script>
    <script src="../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/notebooks/218-vehicle-detection-and-recognition-with-output.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="OpenVINO optimizations for Knowledge graphs" href="219-knowledge-graphs-conve-with-output.html" />
    <link rel="prev" title="Deblur Photos with DeblurGAN-v2 and OpenVINO™" href="217-vision-deblur-with-output.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/get-started-guide.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/openvino-docs/index.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/openvino-docs/index.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notebooks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks-installation.html">
   Installation of OpenVINO™ Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="001-hello-world-with-output.html">
   Hello Image Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002-openvino-api-with-output.html">
   OpenVINO™ Runtime API Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003-hello-segmentation-with-output.html">
   Hello Image Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004-hello-detection-with-output.html">
   Hello Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="101-tensorflow-to-openvino-with-output.html">
   Convert a TensorFlow Model to OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="102-pytorch-onnx-to-openvino-with-output.html">
   Convert a PyTorch Model to ONNX and OpenVINO™ IR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="103-paddle-onnx-to-openvino-classification-with-output.html">
   Convert a PaddlePaddle Model to ONNX and OpenVINO™ IR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="104-model-tools-with-output.html">
   Working with Open Model Zoo Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="105-language-quantize-bert-with-output.html">
   Quantize NLP models with Post-Training Optimization Tool ​in OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="106-auto-device-with-output.html">
   Automatic Device Selection with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="107-speech-recognition-quantization-with-output.html">
   Quantize Speech Recognition Models with OpenVINO™ Post-Training Optimization Tool ​
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="110-ct-segmentation-quantize-nncf-with-output.html">
   Quantize a Segmentation Model and Show Live Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="110-ct-segmentation-quantize-with-output.html">
   Quantize a Segmentation Model and Show Live Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="111-detection-quantization-with-output.html">
   Object Detection Quantization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="112-pytorch-post-training-quantization-nncf-with-output.html">
   Post-Training Quantization of PyTorch models with NNCF
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="113-image-classification-quantization-with-output.html">
   Quantization of Image Classification Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="114-quantization-simplified-mode-with-output.html">
   INT8 Quantization with Post-training Optimization Tool (POT) in Simplified Mode tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="115-async-api-with-output.html">
   Asynchronous Inference with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="201-vision-monodepth-with-output.html">
   Monodepth Estimation with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="202-vision-superresolution-image-with-output.html">
   Single Image Super Resolution with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="202-vision-superresolution-video-with-output.html">
   Video Super Resolution with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="203-meter-reader-with-output.html">
   Industrial Meter Reader
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="204-named-entity-recognition-with-output.html">
   Document Entity Extraction with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="205-vision-background-removal-with-output.html">
   Image Background Removal with U^2-Net and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="206-vision-paddlegan-anime-with-output.html">
   Photos to Anime with PaddleGAN and OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="207-vision-paddlegan-superresolution-with-output.html">
   Super Resolution with PaddleGAN and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="208-optical-character-recognition-with-output.html">
   Optical Character Recognition (OCR) with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="209-handwritten-ocr-with-output.html">
   Handwritten Chinese and Japanese OCR with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="210-ct-scan-live-inference-with-output.html">
   Live Inference and Benchmark CT-scan Data with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="211-speech-to-text-with-output.html">
   Speech to Text with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="212-onnx-style-transfer-with-output.html">
   Style Transfer on ONNX Models with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="214-vision-paddle-classification-with-output.html">
   PaddlePaddle Image Classification with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="215-image-inpainting-with-output.html">
   Image In-painting with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="216-license-plate-recognition-with-output.html">
   License Plate Recognition with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="217-vision-deblur-with-output.html">
   Deblur Photos with DeblurGAN-v2 and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Vehicle Detection And Recognition with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="219-knowledge-graphs-conve-with-output.html">
   OpenVINO optimizations for Knowledge graphs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="220-yolov5-accuracy-check-and-quantization-with-output.html">
   Quantize the Ultralytics YOLOv5 model and check accuracy using the OpenVINO POT API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="221-machine-translation-with-output.html">
   Machine translation demo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="222-vision-image-colorization-with-output.html">
   Image Colorization with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="223-gpt2-text-prediction-with-output.html">
   GPT-2 Text Prediction with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="301-tensorflow-training-openvino-pot-with-output.html">
   Post-Training Quantization with TensorFlow Classification Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="301-tensorflow-training-openvino-with-output.html">
   From Training to Deployment with TensorFlow and OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="302-pytorch-quantization-aware-training-with-output.html">
   Quantization Aware Training with NNCF, using PyTorch framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="305-tensorflow-quantization-aware-training-with-output.html">
   Quantization Aware Training with NNCF, using TensorFlow Framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="401-object-detection-with-output.html">
   Live Object Detection with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="402-pose-estimation-with-output.html">
   Live Human Pose Estimation with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="403-action-recognition-webcam-with-output.html">
   Human Action Recognition with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="405-paddle-ocr-webcam-with-output.html">
   PaddleOCR with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebook_utils-with-output.html">
   Notebook Utils
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Vehicle Detection And Recognition with OpenVINO™
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-models">
   Download Models
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-models">
   Load Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#get-attributes-from-model">
     Get attributes from model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#helper-function">
     Helper function
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-and-display-a-test-image">
     Read and display a test image
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#use-the-detection-model-to-detect-vehicles">
   Use the Detection Model to Detect Vehicles
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#detection-processing">
     Detection Processing
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recognize-vehicle-attributes">
     Recognize vehicle attributes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#recognition-processing">
       Recognition processing
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#combine-two-models">
     Combine two models
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="vehicle-detection-and-recognition-with-openvino">
<h1>Vehicle Detection And Recognition with OpenVINO™<a class="headerlink" href="#vehicle-detection-and-recognition-with-openvino" title="Permalink to this headline">¶</a></h1>
<p>This tutorial demonstrates how to use two pre-trained models from <a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo">Open
Model Zoo</a>:
<a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/vehicle-detection-0200">vehicle-detection-0200</a>
for object detection and
<a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/vehicle-attributes-recognition-barrier-0039">vehicle-attributes-recognition-barrier-0039</a>
for image classification. Using these models, you will detect vehicles
from raw images and recognize attributes of detected vehicles.
<img alt="flowchart" src="https://user-images.githubusercontent.com/47499836/157867076-9e997781-f9ef-45f6-9a51-b515bbf41048.png" /></p>
<p>As a result, you can get:</p>
<figure class="align-default" id="id1">
<img alt="result" src="https://user-images.githubusercontent.com/47499836/157867020-99738b30-62ca-44e2-8d9e-caf13fb724ed.png" />
<figcaption>
<p><span class="caption-text">result</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="imports">
<h1>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h1>
<p>Import the required modules.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import sys
from pathlib import Path
from typing import Tuple

import cv2
import numpy as np
import matplotlib.pyplot as plt
from openvino.runtime import Core

sys.path.append(&quot;../utils&quot;)
import notebook_utils as utils
</pre></div>
</div>
</section>
<section id="download-models">
<h1>Download Models<a class="headerlink" href="#download-models" title="Permalink to this headline">¶</a></h1>
<p>Use <code class="docutils literal notranslate"><span class="pre">omz_downloader</span></code> - a command-line tool from the <code class="docutils literal notranslate"><span class="pre">openvino-dev</span></code>
package. The <code class="docutils literal notranslate"><span class="pre">omz_downloader</span></code> tool automatically creates a directory
structure and downloads the selected model. This step is skipped if the
model is already downloaded. The selected model comes from the public
directory, which means it must be converted into OpenVINO Intermediate
Representation (OpenVINO IR).</p>
<blockquote>
<div><p><strong>Note</strong>: To change the model, replace the name of the model in the
code below, for example to <code class="docutils literal notranslate"><span class="pre">&quot;vehicle-detection-0201&quot;</span></code> or
<code class="docutils literal notranslate"><span class="pre">&quot;vehicle-detection-0202&quot;</span></code>. Keep in mind that they support
different image input sizes in detection. Also, you can change the
recognition model to
<code class="docutils literal notranslate"><span class="pre">&quot;vehicle-attributes-recognition-barrier-0042&quot;</span></code>. They are trained
from different deep learning frames. Therefore, if you want to change
the precision, you need to modify the precision value in <code class="docutils literal notranslate"><span class="pre">&quot;FP32&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;FP16&quot;</span></code>, and <code class="docutils literal notranslate"><span class="pre">&quot;FP16-INT8&quot;</span></code>. A different type has a different
model size and a precision value.</p>
</div></blockquote>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># A directory where the model will be downloaded.
base_model_dir = &quot;model&quot;
# The name of the model from Open Model Zoo.
detection_model_name = &quot;vehicle-detection-0200&quot;
recognition_model_name = &quot;vehicle-attributes-recognition-barrier-0039&quot;
# Selected precision (FP32, FP16, FP16-INT8)
precision = &quot;FP32&quot;

# Check if the model exists.
detection_model_path = (
    f&quot;model/intel/{detection_model_name}/{precision}/{detection_model_name}.xml&quot;
)
recognition_model_path = (
    f&quot;model/intel/{recognition_model_name}/{precision}/{recognition_model_name}.xml&quot;
)

# Download the detection model.
if not os.path.exists(detection_model_path):
    download_command = f&quot;omz_downloader &quot; \
                       f&quot;--name {detection_model_name} &quot; \
                       f&quot;--precision {precision} &quot; \
                       f&quot;--output_dir {base_model_dir}&quot;
    ! $download_command
# Download the recognition model.
if not os.path.exists(recognition_model_path):
    download_command = f&quot;omz_downloader &quot; \
                       f&quot;--name {recognition_model_name} &quot; \
                       f&quot;--precision {precision} &quot; \
                       f&quot;--output_dir {base_model_dir}&quot;
    ! $download_command
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">################|| Downloading vehicle-detection-0200 ||################</span>

<span class="o">==========</span> <span class="n">Downloading</span> <span class="n">model</span><span class="o">/</span><span class="n">intel</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">detection</span><span class="o">-</span><span class="mi">0200</span><span class="o">/</span><span class="n">FP32</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">detection</span><span class="o">-</span><span class="mf">0200.</span><span class="n">xml</span>


<span class="o">==========</span> <span class="n">Downloading</span> <span class="n">model</span><span class="o">/</span><span class="n">intel</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">detection</span><span class="o">-</span><span class="mi">0200</span><span class="o">/</span><span class="n">FP32</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">detection</span><span class="o">-</span><span class="mf">0200.</span><span class="n">bin</span>


<span class="c1">################|| Downloading vehicle-attributes-recognition-barrier-0039 ||################</span>

<span class="o">==========</span> <span class="n">Downloading</span> <span class="n">model</span><span class="o">/</span><span class="n">intel</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">attributes</span><span class="o">-</span><span class="n">recognition</span><span class="o">-</span><span class="n">barrier</span><span class="o">-</span><span class="mi">0039</span><span class="o">/</span><span class="n">FP32</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">attributes</span><span class="o">-</span><span class="n">recognition</span><span class="o">-</span><span class="n">barrier</span><span class="o">-</span><span class="mf">0039.</span><span class="n">xml</span>


<span class="o">==========</span> <span class="n">Downloading</span> <span class="n">model</span><span class="o">/</span><span class="n">intel</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">attributes</span><span class="o">-</span><span class="n">recognition</span><span class="o">-</span><span class="n">barrier</span><span class="o">-</span><span class="mi">0039</span><span class="o">/</span><span class="n">FP32</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">attributes</span><span class="o">-</span><span class="n">recognition</span><span class="o">-</span><span class="n">barrier</span><span class="o">-</span><span class="mf">0039.</span><span class="n">bin</span>
</pre></div>
</div>
</section>
<section id="load-models">
<h1>Load Models<a class="headerlink" href="#load-models" title="Permalink to this headline">¶</a></h1>
<p>This tutorial requires a detection model and a recognition model. After
downloading the models, initialize OpenVINO Runtime, and use
<code class="docutils literal notranslate"><span class="pre">read_network</span></code> to read network architecture and weights from <code class="docutils literal notranslate"><span class="pre">*.xml</span></code>
and <code class="docutils literal notranslate"><span class="pre">*.bin</span></code> files. Then, compile it with <code class="docutils literal notranslate"><span class="pre">compile_model()</span></code> to the
specified device.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Initialize OpenVINO Runtime runtime.
ie_core = Core()


def model_init(model_path: str) -&gt; Tuple:
    &quot;&quot;&quot;
    Read the network and weights from file, load the
    model on the CPU and get input and output names of nodes

    :param: model: model architecture path *.xml
    :retuns:
            input_key: Input node network
            output_key: Output node network
            exec_net: Encoder model network
            net: Model network
    &quot;&quot;&quot;

    # Read the network and corresponding weights from a file.
    model = ie_core.read_model(model=model_path)
    # Compile the model for CPU (you can use GPU or MYRIAD as well).
    compiled_model = ie_core.compile_model(model=model, device_name=&quot;CPU&quot;)
    # Get input and output names of nodes.
    input_keys = compiled_model.input(0)
    output_keys = compiled_model.output(0)
    return input_keys, output_keys, compiled_model
</pre></div>
</div>
<section id="get-attributes-from-model">
<h2>Get attributes from model<a class="headerlink" href="#get-attributes-from-model" title="Permalink to this headline">¶</a></h2>
<p>Use <code class="docutils literal notranslate"><span class="pre">input_keys.shape</span></code> to get data shapes.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># de -&gt; detection
# re -&gt; recognition
# Detection model initialization.
input_key_de, output_keys_de, compiled_model_de = model_init(detection_model_path)
# Recognition model initialization.
input_key_re, output_keys_re, compiled_model_re = model_init(recognition_model_path)

# Get input size - Detection.
height_de, width_de = list(input_key_de.shape)[2:]
# Get input size - Recognition.
height_re, width_re = list(input_key_re.shape)[2:]
</pre></div>
</div>
</section>
<section id="helper-function">
<h2>Helper function<a class="headerlink" href="#helper-function" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">plt_show()</span></code> function is used to show image.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plt_show(raw_image):
    &quot;&quot;&quot;
    Use matplot to show image inline
    raw_image: input image

    :param: raw_image:image array
    &quot;&quot;&quot;
    plt.figure(figsize=(10, 6))
    plt.axis(&quot;off&quot;)
    plt.imshow(raw_image)
</pre></div>
</div>
</section>
<section id="read-and-display-a-test-image">
<h2>Read and display a test image<a class="headerlink" href="#read-and-display-a-test-image" title="Permalink to this headline">¶</a></h2>
<p>The input shape of detection model is <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">3,</span> <span class="pre">256,</span> <span class="pre">256]</span></code>. Therefore,
you need to resize the image to <code class="docutils literal notranslate"><span class="pre">256</span> <span class="pre">x</span> <span class="pre">256</span></code>, and expand the batch
channel with <code class="docutils literal notranslate"><span class="pre">expand_dims</span></code> function.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Load an image.
url = &quot;https://storage.openvinotoolkit.org/data/test_data/images/person-bicycle-car-detection.bmp&quot;
filename = &quot;cars.jpg&quot;
directory = &quot;data&quot;
image_file = utils.download_file(
    url, filename=filename, directory=directory, show_progress=False, silent=True,timeout=30
)
assert Path(image_file).exists()

# Read the image.
image_de = cv2.imread(&quot;data/cars.jpg&quot;)
# Resize it to [3, 256, 256].
resized_image_de = cv2.resize(image_de, (width_de, height_de))
# Expand the batch channel to [1, 3, 256, 256].
input_image_de = np.expand_dims(resized_image_de.transpose(2, 0, 1), 0)
# Show the image.
plt_show(cv2.cvtColor(image_de, cv2.COLOR_BGR2RGB))
</pre></div>
</div>
<img alt="../_images/218-vehicle-detection-and-recognition-with-output_12_0.png" src="../_images/218-vehicle-detection-and-recognition-with-output_12_0.png" />
</section>
</section>
<section id="use-the-detection-model-to-detect-vehicles">
<h1>Use the Detection Model to Detect Vehicles<a class="headerlink" href="#use-the-detection-model-to-detect-vehicles" title="Permalink to this headline">¶</a></h1>
<figure class="align-default" id="id2">
<img alt="pipline" src="https://user-images.githubusercontent.com/47499836/157867076-9e997781-f9ef-45f6-9a51-b515bbf41048.png" />
<figcaption>
<p><span class="caption-text">pipline</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>As shown in the flowchart, images of individual vehicles are sent to the
recognition model. First, use <code class="docutils literal notranslate"><span class="pre">infer</span></code> function to get the result.</p>
<p>The detection model output has the format [image_id, label, conf, x_min,
y_min, x_max, y_max], where:</p>
<ul class="simple">
<li><p>image_id - ID of the image in the batch</p></li>
<li><p>label - predicted class ID (0 - vehicle)</p></li>
<li><p>conf - confidence for the predicted class</p></li>
<li><p>(x_min, y_min) - coordinates of the top left bounding box corner</p></li>
<li><p>(x_max, y_max) - coordinates of the bottom right bounding box corner</p></li>
</ul>
<p>Delete unused dims and filter out results that are not used.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Run inference.
boxes = compiled_model_de([input_image_de])[output_keys_de]
# Delete the dim of 0, 1.
boxes = np.squeeze(boxes, (0, 1))
# Remove zero only boxes.
boxes = boxes[~np.all(boxes == 0, axis=1)]
</pre></div>
</div>
<section id="detection-processing">
<h2>Detection Processing<a class="headerlink" href="#detection-processing" title="Permalink to this headline">¶</a></h2>
<p>With the function below, you change the ratio to the real position in
the image and filter out low-confidence results.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def crop_images(bgr_image, resized_image, boxes, threshold=0.6) -&gt; np.ndarray:
    &quot;&quot;&quot;
    Use bounding boxes from detection model to find the absolute car position

    :param: bgr_image: raw image
    :param: resized_image: resized image
    :param: boxes: detection model returns rectangle position
    :param: threshold: confidence threshold
    :returns: car_position: car&#39;s absolute position
    &quot;&quot;&quot;
    # Fetch image shapes to calculate ratio
    (real_y, real_x), (resized_y, resized_x) = bgr_image.shape[:2], resized_image.shape[:2]
    ratio_x, ratio_y = real_x / resized_x, real_y / resized_y

    # Find the boxes ratio
    boxes = boxes[:, 2:]
    # Store the vehicle&#39;s position
    car_position = []
    # Iterate through non-zero boxes
    for box in boxes:
        # Pick confidence factor from last place in array
        conf = box[0]
        if conf &gt; threshold:
            # Convert float to int and multiply corner position of each box by x and y ratio
            # In case that bounding box is found at the top of the image,
            # we position upper box bar little bit lower to make it visible on image
            (x_min, y_min, x_max, y_max) = [
                int(max(corner_position * ratio_y * resized_y, 10)) if idx % 2
                else int(corner_position * ratio_x * resized_x)
                for idx, corner_position in enumerate(box[1:])
            ]

            car_position.append([x_min, y_min, x_max, y_max])

    return car_position
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Find the position of a car.
car_position = crop_images(image_de, resized_image_de, boxes)
</pre></div>
</div>
</section>
<section id="recognize-vehicle-attributes">
<h2>Recognize vehicle attributes<a class="headerlink" href="#recognize-vehicle-attributes" title="Permalink to this headline">¶</a></h2>
<p>Select one of the detected boxes. Then, crop to an area containing a
vehicle to test with the recognition model. Again, you need to resize
the input image and run inference.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Select a vehicle to recognize.
pos = car_position[0]
# Crop the image with [y_min:y_max, x_min:x_max].
test_car = image_de[pos[1]:pos[3], pos[0]:pos[2]]
# Resize the image to input_size.
resized_image_re = cv2.resize(test_car, (width_re, height_re))
input_image_re = np.expand_dims(resized_image_re.transpose(2, 0, 1), 0)
plt_show(cv2.cvtColor(resized_image_re, cv2.COLOR_BGR2RGB))
</pre></div>
</div>
<img alt="../_images/218-vehicle-detection-and-recognition-with-output_19_0.png" src="../_images/218-vehicle-detection-and-recognition-with-output_19_0.png" />
<section id="recognition-processing">
<h3>Recognition processing<a class="headerlink" href="#recognition-processing" title="Permalink to this headline">¶</a></h3>
<p>The result contains colors of the vehicles (white, gray, yellow, red,
green, blue, black) and types of vehicles (car, bus, truck, van). Next,
you need to calculate the probability of each attribute. Then, you
determine the maximum probability as the result.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def vehicle_recognition(compiled_model_re, input_size, raw_image):
    &quot;&quot;&quot;
    Vehicle attributes recognition, input a single vehicle, return attributes
    :param: compiled_model_re: recognition net
    :param: input_size: recognition input size
    :param: raw_image: single vehicle image
    :returns: attr_color: predicted color
                       attr_type: predicted type
    &quot;&quot;&quot;
    # An attribute of a vehicle.
    colors = [&#39;White&#39;, &#39;Gray&#39;, &#39;Yellow&#39;, &#39;Red&#39;, &#39;Green&#39;, &#39;Blue&#39;, &#39;Black&#39;]
    types = [&#39;Car&#39;, &#39;Bus&#39;, &#39;Truck&#39;, &#39;Van&#39;]

    # Resize the image to input size.
    resized_image_re = cv2.resize(raw_image, input_size)
    input_image_re = np.expand_dims(resized_image_re.transpose(2, 0, 1), 0)

    # Run inference.
    # Predict result.
    predict_colors = compiled_model_re([input_image_re])[compiled_model_re.output(1)]
    # Delete the dim of 2, 3.
    predict_colors = np.squeeze(predict_colors, (2, 3))
    predict_types = compiled_model_re([input_image_re])[compiled_model_re.output(0)]
    predict_types = np.squeeze(predict_types, (2, 3))

    attr_color, attr_type = (colors[np.argmax(predict_colors)],
                             types[np.argmax(predict_types)])
    return attr_color, attr_type
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(f&quot;Attributes:{vehicle_recognition(compiled_model_re, (72, 72), test_car)}&quot;)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Attributes</span><span class="p">:(</span><span class="s1">&#39;Gray&#39;</span><span class="p">,</span> <span class="s1">&#39;Car&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="combine-two-models">
<h2>Combine two models<a class="headerlink" href="#combine-two-models" title="Permalink to this headline">¶</a></h2>
<p>Congratulations! You successfully used a detection model to crop an
image with a vehicle and recognize the attributes of a vehicle.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def convert_result_to_image(compiled_model_re, bgr_image, resized_image, boxes, threshold=0.6):
    &quot;&quot;&quot;
    Use Detection model boxes to draw rectangles and plot the result

    :param: compiled_model_re: recognition net
    :param: input_key_re: recognition input key
    :param: bgr_image: raw image
    :param: resized_image: resized image
    :param: boxes: detection model returns rectangle position
    :param: threshold: confidence threshold
    :returns: rgb_image: processed image
    &quot;&quot;&quot;
    # Define colors for boxes and descriptions.
    colors = {&quot;red&quot;: (255, 0, 0), &quot;green&quot;: (0, 255, 0)}

    # Convert the base image from BGR to RGB format.
    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)

    # Find positions of cars.
    car_position = crop_images(image_de, resized_image, boxes)

    for x_min, y_min, x_max, y_max in car_position:
        # Run vehicle recognition inference.
        attr_color, attr_type = vehicle_recognition(compiled_model_re, (72, 72),
                                                    image_de[y_min:y_max, x_min:x_max])

        # Close the window with a vehicle.
        plt.close()

        # Draw a bounding box based on position.
        # Parameters in the `rectangle` function are: image, start_point, end_point, color, thickness.
        rgb_image = cv2.rectangle(rgb_image, (x_min, y_min), (x_max, y_max), colors[&quot;red&quot;], 2)

        # Print the attributes of a vehicle.
        # Parameters in the `putText` function are: img, text, org, fontFace, fontScale, color, thickness, lineType.
        rgb_image = cv2.putText(
            rgb_image,
            f&quot;{attr_color} {attr_type}&quot;,
            (x_min, y_min - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            2,
            colors[&quot;green&quot;],
            10,
            cv2.LINE_AA
        )

    return rgb_image
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt_show(convert_result_to_image(compiled_model_re, image_de, resized_image_de, boxes))
</pre></div>
</div>
<img alt="../_images/218-vehicle-detection-and-recognition-with-output_25_0.png" src="../_images/218-vehicle-detection-and-recognition-with-output_25_0.png" />
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="217-vision-deblur-with-output.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="219-knowledge-graphs-conve-with-output.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>